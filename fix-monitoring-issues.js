// Complete Fix for Monitoring Issues
// Run this in browser console when Velvet is running

console.log('ðŸ”§ COMPLETE MONITORING SYSTEM FIX');
console.log('================================');

async function fixAllMonitoringIssues() {
    console.log('ðŸ” Step 1: Diagnosing Current Issues...');
    
    // Check what's currently loaded
    const hasScreenOCR = typeof RealScreenOCRMonitor !== 'undefined';
    const hasAudioMonitor = typeof RealAudioEnvironmentMonitor !== 'undefined';
    const hasContextEngine = typeof UnifiedContextEngine !== 'undefined';
    const hasTesseract = typeof Tesseract !== 'undefined';
    
    console.log('ðŸ“Š System Status:');
    console.log(`  â€¢ Screen OCR Class: ${hasScreenOCR ? 'âœ…' : 'âŒ'}`);
    console.log(`  â€¢ Audio Monitor Class: ${hasAudioMonitor ? 'âœ…' : 'âŒ'}`);
    console.log(`  â€¢ Context Engine Class: ${hasContextEngine ? 'âœ…' : 'âŒ'}`);
    console.log(`  â€¢ Tesseract.js: ${hasTesseract ? 'âœ…' : 'âŒ'}`);
    
    // Check existing instances
    const hasScreenInstance = window.screenOCRMonitor !== undefined;
    const hasAudioInstance = window.audioEnvironmentMonitor !== undefined;
    const hasContextInstance = window.unifiedContextEngine !== undefined;
    
    console.log('\nðŸ“± Current Instances:');
    console.log(`  â€¢ Screen OCR Instance: ${hasScreenInstance ? 'âœ…' : 'âŒ'}`);
    console.log(`  â€¢ Audio Monitor Instance: ${hasAudioInstance ? 'âœ…' : 'âŒ'}`);
    console.log(`  â€¢ Context Engine Instance: ${hasContextInstance ? 'âœ…' : 'âŒ'}`);
    
    if (!hasScreenOCR || !hasAudioMonitor || !hasContextEngine) {
        console.error('âŒ Missing required classes - check script loading');
        return;
    }
    
    console.log('\nðŸ”§ Step 2: Force Stop All Existing Monitoring...');
    
    // Stop existing monitors
    if (window.screenOCRMonitor) {
        try {
            await window.screenOCRMonitor.deactivate();
            console.log('âœ… Stopped existing screen OCR monitor');
        } catch (e) {
            console.log('âš ï¸ Error stopping screen OCR:', e.message);
        }
    }
    
    if (window.audioEnvironmentMonitor) {
        try {
            await window.audioEnvironmentMonitor.deactivate();
            console.log('âœ… Stopped existing audio monitor');
        } catch (e) {
            console.log('âš ï¸ Error stopping audio monitor:', e.message);
        }
    }
    
    if (window.unifiedContextEngine) {
        try {
            window.unifiedContextEngine.deactivate();
            console.log('âœ… Stopped existing context engine');
        } catch (e) {
            console.log('âš ï¸ Error stopping context engine:', e.message);
        }
    }
    
    console.log('\nðŸš€ Step 3: Initialize Fresh Monitoring System...');
    
    try {
        // Create new screen OCR monitor
        console.log('ðŸ‘ï¸ Creating fresh Screen OCR Monitor...');
        const screenMonitor = new RealScreenOCRMonitor();
        
        console.log('ðŸ”§ Initializing Screen OCR...');
        const screenInit = await screenMonitor.initialize();
        if (!screenInit) {
            throw new Error('Screen OCR initialization failed');
        }
        console.log('âœ… Screen OCR initialized successfully');
        
        // Create new audio monitor
        console.log('ðŸŽ§ Creating fresh Audio Environment Monitor...');
        const audioMonitor = new RealAudioEnvironmentMonitor();
        
        console.log('ðŸ”§ Initializing Audio Monitor...');
        const audioInit = await audioMonitor.initialize();
        if (!audioInit) {
            throw new Error('Audio monitor initialization failed');
        }
        console.log('âœ… Audio monitor initialized successfully');
        
        // Create new context engine
        console.log('ðŸ§  Creating fresh Unified Context Engine...');
        const contextEngine = new UnifiedContextEngine();
        
        console.log('ðŸ”§ Initializing Context Engine...');
        const contextInit = await contextEngine.initialize(screenMonitor, audioMonitor);
        if (!contextInit) {
            throw new Error('Context engine initialization failed');
        }
        console.log('âœ… Context engine initialized successfully');
        
        console.log('\nðŸŽ¯ Step 4: Start All Monitoring...');
        
        // Start screen monitoring (will request permission)
        console.log('ðŸ“¸ Starting Screen OCR monitoring...');
        console.log('ðŸ’¡ IMPORTANT: Allow screen sharing when prompted!');
        const screenStarted = await screenMonitor.startMonitoring();
        
        if (screenStarted) {
            console.log('âœ… Screen OCR monitoring ACTIVE');
        } else {
            console.log('âŒ Screen OCR monitoring failed to start');
        }
        
        // Start audio monitoring
        console.log('ðŸŽµ Starting Audio Environment monitoring...');
        const audioStarted = await audioMonitor.startMonitoring();
        
        if (audioStarted) {
            console.log('âœ… Audio Environment monitoring ACTIVE');
        } else {
            console.log('âŒ Audio Environment monitoring failed to start');
        }
        
        // Store references globally
        window.screenOCRMonitor = screenMonitor;
        window.audioEnvironmentMonitor = audioMonitor;
        window.unifiedContextEngine = contextEngine;
        
        console.log('\nâœ… MONITORING SYSTEM FULLY OPERATIONAL!');
        console.log('=======================================');
        console.log('ðŸŽ¯ What to expect now:');
        console.log('  â€¢ Screen OCR: "ðŸ“¸ Capturing real screen..." every 5 seconds');
        console.log('  â€¢ Audio Detection: "ðŸŽµ System audio:" messages every 3 seconds');
        console.log('  â€¢ Context Updates: "ðŸ§  Unified context updated:" messages');
        console.log('');
        console.log('ðŸ“Š To view monitoring data:');
        console.log('  â€¢ Screen text: window.screenOCRMonitor.textHistory');
        console.log('  â€¢ Audio context: window.audioEnvironmentMonitor.audioHistory');
        console.log('  â€¢ Unified context: window.unifiedContextEngine.contextHistory');
        console.log('');
        console.log('ðŸ›‘ To stop monitoring:');
        console.log('  â€¢ Screen: window.screenOCRMonitor.stopMonitoring()');
        console.log('  â€¢ Audio: window.audioEnvironmentMonitor.stopMonitoring()');
        console.log('  â€¢ Context: window.unifiedContextEngine.stop()');
        
        // Set up monitoring for results
        setupMonitoringWatcher();
        
        return true;
        
    } catch (error) {
        console.error('âŒ Monitoring system initialization failed:', error);
        console.error('ðŸ’¡ Try refreshing the app and running this script again');
        return false;
    }
}

function setupMonitoringWatcher() {
    console.log('\nðŸ‘€ Setting up monitoring watcher...');
    
    // Check for screen OCR activity
    let lastScreenText = '';
    let lastAudioContext = '';
    let lastUnifiedContext = '';
    
    setInterval(() => {
        // Check screen OCR progress
        if (window.screenOCRMonitor && window.screenOCRMonitor.textHistory.length > 0) {
            const latest = window.screenOCRMonitor.textHistory[window.screenOCRMonitor.textHistory.length - 1];
            const newText = latest.text.substring(0, 50);
            
            if (newText !== lastScreenText) {
                console.log(`ðŸ“ NEW SCREEN TEXT: "${newText}..." (confidence: ${latest.confidence?.toFixed(2)})`);
                lastScreenText = newText;
            }
        }
        
        // Check audio context progress
        if (window.audioEnvironmentMonitor && window.audioEnvironmentMonitor.audioHistory.length > 0) {
            const latest = window.audioEnvironmentMonitor.audioHistory[window.audioEnvironmentMonitor.audioHistory.length - 1];
            const newContext = `${latest.primaryType} from ${latest.source}`;
            
            if (newContext !== lastAudioContext) {
                console.log(`ðŸŽµ NEW AUDIO CONTEXT: ${newContext} (confidence: ${latest.confidence?.toFixed(2)})`);
                lastAudioContext = newContext;
            }
        }
        
        // Check unified context progress
        if (window.unifiedContextEngine && window.unifiedContextEngine.contextHistory.length > 0) {
            const latest = window.unifiedContextEngine.contextHistory[window.unifiedContextEngine.contextHistory.length - 1];
            const newUnified = `${latest.unified.primaryContext} (${latest.correlation.confidence.toFixed(2)})`;
            
            if (newUnified !== lastUnifiedContext) {
                console.log(`ðŸ§  NEW UNIFIED CONTEXT: ${newUnified}`);
                lastUnifiedContext = newUnified;
            }
        }
        
    }, 10000); // Check every 10 seconds
    
    console.log('âœ… Monitoring watcher active - will report new detections');
}

// Export for manual use
window.fixAllMonitoringIssues = fixAllMonitoringIssues;

console.log('ðŸ’¡ Run: fixAllMonitoringIssues() to fix all monitoring issues');