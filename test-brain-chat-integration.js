// Test script to verify brain-chat integration
// Open developer console in Velvet app and run this script

console.log('üß™ TESTING BRAIN-CHAT INTEGRATION');
console.log('=================================');

async function testBrainChatIntegration() {
    console.log('üìã 1. Testing chat AI system...');
    
    if (typeof window.getVelvetResponse === 'function') {
        console.log('‚úÖ getVelvetResponse function available');
        
        try {
            console.log('üì§ Sending test message to AI...');
            const testMessage = "Hi, can you see what's on my screen right now?";
            const response = await window.getVelvetResponse(testMessage);
            
            console.log('üì• AI Response received:', response);
            
            // Check if response indicates screen awareness
            const hasScreenAwareness = response.toLowerCase().includes('screen') || 
                                     response.toLowerCase().includes('see') ||
                                     response.toLowerCase().includes('aware') ||
                                     response.toLowerCase().includes('monitor');
                                     
            if (hasScreenAwareness) {
                console.log('‚úÖ AI shows screen awareness in response');
            } else {
                console.log('‚ö†Ô∏è AI response doesn\'t indicate screen awareness');
            }
            
        } catch (error) {
            console.error('‚ùå Chat AI test failed:', error);
        }
    } else {
        console.error('‚ùå getVelvetResponse function not available');
    }
    
    console.log('\nüìã 2. Testing brain status...');
    console.log('   Brain available:', typeof window.velvetBrain);
    console.log('   Brain active:', window.velvetBrain?.isActive);
    console.log('   Screen OCR available:', typeof window.screenOCRMonitor);
    console.log('   Screen OCR active:', window.screenOCRMonitor?.isActive);
    console.log('   Current screen text length:', window.screenOCRMonitor?.currentScreenText?.length);
    
    console.log('\nüìã 3. Testing brain context method...');
    if (window.velvetAI && typeof window.velvetAI.getBrainContext === 'function') {
        try {
            const context = await window.velvetAI.getBrainContext();
            console.log('‚úÖ getBrainContext method works');
            console.log('   Context preview:', context.substring(0, 200) + '...');
            
            if (context.includes('SCREEN CONTENT') || context.includes('SCREEN AWARENESS')) {
                console.log('‚úÖ Brain context includes screen data');
            } else {
                console.log('‚ö†Ô∏è Brain context missing screen data');
            }
        } catch (error) {
            console.error('‚ùå getBrainContext test failed:', error);
        }
    } else {
        console.error('‚ùå getBrainContext method not available');
    }
    
    console.log('\n=================================');
    console.log('üß™ Integration test complete');
    console.log('Check the logs above for any issues');
}

testBrainChatIntegration();