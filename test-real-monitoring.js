// Test script to see exactly what Velvet is reading and hearing
// Run this in the browser console to see real monitoring logs

console.log('üß™ REAL MONITORING TEST SCRIPT');
console.log('===============================');

// Test 1: Check if systems are loaded
function checkSystemStatus() {
    console.log('\nüìã SYSTEM STATUS CHECK:');
    console.log('‚Ä¢ Tesseract loaded:', typeof Tesseract !== 'undefined' ? '‚úÖ' : '‚ùå');
    console.log('‚Ä¢ Electron API loaded:', typeof window.electronAPI !== 'undefined' ? '‚úÖ' : '‚ùå');
    console.log('‚Ä¢ Screen OCR class loaded:', typeof RealScreenOCRMonitor !== 'undefined' ? '‚úÖ' : '‚ùå');
    console.log('‚Ä¢ Audio Monitor class loaded:', typeof RealAudioEnvironmentMonitor !== 'undefined' ? '‚úÖ' : '‚ùå');
    console.log('‚Ä¢ Context Engine loaded:', typeof UnifiedContextEngine !== 'undefined' ? '‚úÖ' : '‚ùå');
}

// Test 2: Initialize and test REAL screen OCR
async function testRealScreenOCR() {
    console.log('\nüëÅÔ∏è TESTING REAL SCREEN OCR:');
    console.log('=============================');
    
    try {
        const monitor = new RealScreenOCRMonitor();
        console.log('üîß Initializing OCR monitor...');
        
        const initialized = await monitor.initialize();
        if (!initialized) {
            console.error('‚ùå Failed to initialize screen OCR');
            return;
        }
        
        console.log('‚úÖ Screen OCR initialized successfully');
        console.log('üéØ Starting screen capture (permission will be requested)...');
        
        const started = await monitor.startMonitoring();
        if (started) {
            console.log('‚úÖ REAL screen monitoring started!');
            console.log('üì∏ Velvet will now capture your screen every 5 seconds');
            console.log('üîç OCR will extract text from everything visible');
            console.log('');
            console.log('üí° WATCH FOR THESE LOGS:');
            console.log('  üì∏ Capturing real screen...');
            console.log('  üîç Running Tesseract OCR...');
            console.log('  ‚úÖ Real screen OCR completed in Xms - confidence: Y');
            console.log('  üìù REAL screen text processed: [actual text from your screen]');
            console.log('  üéØ Relevance: X.XX, Context: [detected context]');
            
            // Store reference for later use
            window.testScreenMonitor = monitor;
            
            return true;
        }
    } catch (error) {
        console.error('‚ùå Screen OCR test failed:', error);
        return false;
    }
}

// Test 3: Initialize and test REAL audio monitoring
async function testRealAudioMonitoring() {
    console.log('\nüéß TESTING REAL AUDIO MONITORING:');
    console.log('=================================');
    
    try {
        const monitor = new RealAudioEnvironmentMonitor();
        console.log('üîß Initializing audio monitor...');
        
        const initialized = await monitor.initialize();
        if (!initialized) {
            console.error('‚ùå Failed to initialize audio monitor');
            return;
        }
        
        console.log('‚úÖ Audio monitor initialized successfully');
        console.log('üéµ Starting system audio detection...');
        
        const started = await monitor.startMonitoring();
        if (started) {
            console.log('‚úÖ REAL audio monitoring started!');
            console.log('üîä Velvet will now detect your system audio every 3 seconds');
            console.log('üéµ Detects: Spotify, Apple Music, YouTube, calls, etc.');
            console.log('üé§ Also analyzes microphone for ambient audio');
            console.log('');
            console.log('üí° WATCH FOR THESE LOGS:');
            console.log('  üéµ Getting current audio context...');
            console.log('  ‚úÖ Audio context: music (Spotify)');
            console.log('  üîä Audio source: music from Spotify');
            console.log('  üéß Audio analysis completed in Xms - detected: music');
            console.log('  üéµ REAL audio context: music from system_detection - enhancing');
            
            // Store reference for later use
            window.testAudioMonitor = monitor;
            
            return true;
        }
    } catch (error) {
        console.error('‚ùå Audio monitoring test failed:', error);
        return false;
    }
}

// Test 4: Test system audio detection directly
async function testSystemAudioDirect() {
    console.log('\nüîä TESTING SYSTEM AUDIO DETECTION DIRECTLY:');
    console.log('==========================================');
    
    if (!window.electronAPI || !window.electronAPI.audioEnvironment) {
        console.error('‚ùå Electron Audio API not available');
        return;
    }
    
    try {
        console.log('üéµ Getting current audio context...');
        const audioContext = await window.electronAPI.audioEnvironment.getCurrentAudioContext();
        console.log('üìä Audio Context Result:', audioContext);
        
        console.log('üîä Capturing system audio sources...');
        const audioSources = await window.electronAPI.audioEnvironment.captureSystemAudio();
        console.log('üìä Audio Sources Result:', audioSources);
        
        console.log('üéß Getting system audio devices...');
        const audioDevices = await window.electronAPI.audioEnvironment.getSystemAudioDevices();
        console.log('üìä Audio Devices Result:', audioDevices);
        
        // Interpret results
        console.log('\nüéØ INTERPRETATION:');
        if (audioContext.context === 'music') {
            console.log(`üéµ Music detected: ${audioContext.currentTrack} (${audioContext.app})`);
        } else if (audioContext.context === 'silence') {
            console.log('üîá No music currently playing');
        }
        
        if (audioSources.audioSources && audioSources.audioSources.length > 0) {
            console.log(`üîä Active audio apps: ${audioSources.audioSources.map(s => s.name).join(', ')}`);
        } else {
            console.log('üîá No active audio applications detected');
        }
        
        return true;
    } catch (error) {
        console.error('‚ùå System audio detection failed:', error);
        return false;
    }
}

// Test 5: View monitoring history
function viewMonitoringHistory() {
    console.log('\nüìö VIEWING MONITORING HISTORY:');
    console.log('==============================');
    
    if (window.testScreenMonitor && window.testScreenMonitor.textHistory) {
        console.log(`üëÅÔ∏è Screen OCR History (${window.testScreenMonitor.textHistory.length} entries):`);
        window.testScreenMonitor.textHistory.slice(-3).forEach((entry, i) => {
            console.log(`  ${i + 1}. [${new Date(entry.timestamp).toLocaleTimeString()}] "${entry.text.substring(0, 100)}..."`);
            console.log(`     Context: ${entry.context.type}, Relevance: ${entry.relevance.score.toFixed(2)}`);
        });
    } else {
        console.log('üëÅÔ∏è No screen OCR history available yet');
    }
    
    if (window.testAudioMonitor && window.testAudioMonitor.audioHistory) {
        console.log(`üéß Audio History (${window.testAudioMonitor.audioHistory.length} entries):`);
        window.testAudioMonitor.audioHistory.slice(-3).forEach((entry, i) => {
            console.log(`  ${i + 1}. [${new Date(entry.timestamp).toLocaleTimeString()}] ${entry.primaryType} from ${entry.source}`);
            console.log(`     Focus Impact: ${entry.insights.focusImpact}, Relevance: ${entry.relevance.score.toFixed(2)}`);
        });
    } else {
        console.log('üéß No audio history available yet');
    }
}

// Main test runner
async function runCompleteTest() {
    console.clear();
    console.log('üöÄ COMPLETE REAL MONITORING TEST');
    console.log('================================');
    console.log('This will test ALL real monitoring capabilities');
    console.log('');
    
    // Check system status
    checkSystemStatus();
    
    // Test system audio first (doesn't require permissions)
    await testSystemAudioDirect();
    
    // Wait a moment
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    // Test audio monitoring (may require microphone permission)
    const audioWorking = await testRealAudioMonitoring();
    
    // Wait a moment
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    // Test screen OCR (will require screen capture permission)
    const screenWorking = await testRealScreenOCR();
    
    // Final instructions
    console.log('\nüéØ TEST COMPLETE - MONITORING IS NOW ACTIVE!');
    console.log('============================================');
    console.log('');
    if (screenWorking) {
        console.log('üëÅÔ∏è SCREEN MONITORING: Active - capturing every 5 seconds');
        console.log('  ‚Ä¢ Open different apps (email, code editor, browser)');
        console.log('  ‚Ä¢ Type some text');
        console.log('  ‚Ä¢ Watch console for OCR results');
    }
    if (audioWorking) {
        console.log('üéß AUDIO MONITORING: Active - detecting every 3 seconds');
        console.log('  ‚Ä¢ Play music on Spotify or Apple Music');
        console.log('  ‚Ä¢ Join a video call');
        console.log('  ‚Ä¢ Watch console for audio detection');
    }
    console.log('');
    console.log('üìö TO VIEW HISTORY: run viewMonitoringHistory()');
    console.log('üîÑ TO CHECK STATUS AGAIN: run checkSystemStatus()');
    console.log('');
    console.log('üí° Velvet is now ACTUALLY monitoring your screen and audio!');
}

// Export functions for manual use
window.testRealMonitoring = {
    runComplete: runCompleteTest,
    checkStatus: checkSystemStatus,
    testScreen: testRealScreenOCR,
    testAudio: testRealAudioMonitoring,
    testSystemAudio: testSystemAudioDirect,
    viewHistory: viewMonitoringHistory
};

console.log('üß™ Real Monitoring Test Script Loaded');
console.log('üí° Run: testRealMonitoring.runComplete() to start complete test');
console.log('üí° Or run individual tests: testRealMonitoring.testScreen(), etc.');