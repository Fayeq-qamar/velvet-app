// View Current Screen OCR and Audio Transcripts
// Run this in browser console to see what Velvet is actually detecting

console.log('üìä VELVET TRANSCRIPT VIEWER');
console.log('===========================');

function viewAllTranscripts() {
    console.log('üîç Checking for existing monitoring data...\n');
    
    // Check Screen OCR History
    console.log('üëÅÔ∏è SCREEN OCR TRANSCRIPTS:');
    console.log('==========================');
    
    if (window.screenOCRMonitor && window.screenOCRMonitor.textHistory) {
        const screenHistory = window.screenOCRMonitor.textHistory;
        console.log(`üìù Found ${screenHistory.length} screen text entries`);
        
        if (screenHistory.length > 0) {
            console.log('\nüìú Recent Screen Text (last 5 entries):');
            screenHistory.slice(-5).forEach((entry, i) => {
                const time = new Date(entry.timestamp).toLocaleTimeString();
                const preview = entry.text.substring(0, 100);
                console.log(`${i + 1}. [${time}] "${preview}..."`);
                console.log(`   üìä Confidence: ${entry.confidence?.toFixed(2)}, Context: ${entry.context?.type}`);
                console.log(`   üéØ Relevance: ${entry.relevance?.score?.toFixed(2)} (${entry.relevance?.isRelevant ? 'relevant' : 'not relevant'})`);
                console.log('');
            });
        } else {
            console.log('‚ùå No screen text captured yet');
            console.log('üí° Screen OCR may not be running or no text detected');
        }
    } else {
        console.log('‚ùå Screen OCR monitor not found or not initialized');
        console.log('üí° Try running the fix script first');
    }
    
    console.log('\nüéß AUDIO ENVIRONMENT TRANSCRIPTS:');
    console.log('=================================');
    
    if (window.audioEnvironmentMonitor && window.audioEnvironmentMonitor.audioHistory) {
        const audioHistory = window.audioEnvironmentMonitor.audioHistory;
        console.log(`üéµ Found ${audioHistory.length} audio context entries`);
        
        if (audioHistory.length > 0) {
            console.log('\nüé∂ Recent Audio Context (last 5 entries):');
            audioHistory.slice(-5).forEach((entry, i) => {
                const time = new Date(entry.timestamp).toLocaleTimeString();
                console.log(`${i + 1}. [${time}] ${entry.primaryType} from ${entry.source}`);
                console.log(`   üìä Confidence: ${entry.confidence?.toFixed(2)}`);
                console.log(`   üéØ Focus Impact: ${entry.insights?.focusImpact}, Mood: ${entry.insights?.moodImpact}`);
                console.log(`   üìà Relevance: ${entry.relevance?.score?.toFixed(2)} (${entry.relevance?.isRelevant ? 'relevant' : 'not relevant'})`);
                if (entry.details && Object.keys(entry.details).length > 0) {
                    console.log(`   üîç Details:`, entry.details);
                }
                console.log('');
            });
        } else {
            console.log('‚ùå No audio context captured yet');
            console.log('üí° Audio monitoring may not be running');
        }
    } else {
        console.log('‚ùå Audio Environment monitor not found or not initialized');
        console.log('üí° Try running the fix script first');
    }
    
    console.log('\nüß† UNIFIED CONTEXT HISTORY:');
    console.log('============================');
    
    if (window.unifiedContextEngine && window.unifiedContextEngine.contextHistory) {
        const contextHistory = window.unifiedContextEngine.contextHistory;
        console.log(`üîó Found ${contextHistory.length} unified context entries`);
        
        if (contextHistory.length > 0) {
            console.log('\nüéØ Recent Unified Context (last 5 entries):');
            contextHistory.slice(-5).forEach((entry, i) => {
                const time = new Date(entry.timestamp).toLocaleTimeString();
                console.log(`${i + 1}. [${time}] ${entry.unified.primaryContext}`);
                console.log(`   üîó Correlation: ${entry.correlation.confidence.toFixed(2)} confidence${entry.correlation.pattern ? ` (${entry.correlation.pattern})` : ''}`);
                console.log(`   üèÉ Activity: ${entry.unified.activity}, Environment: ${entry.unified.environment}`);
                console.log(`   üßò Focus: ${entry.unified.focusLevel}, Mood: ${entry.unified.mood}`);
                console.log(`   ‚ö° Urgency: ${entry.urgency.level} (score: ${entry.urgency.score.toFixed(2)})`);
                if (entry.insights.suggestions.length > 0) {
                    console.log(`   üí° Suggestions: ${entry.insights.suggestions.map(s => s.text).join(', ')}`);
                }
                console.log('');
            });
        } else {
            console.log('‚ùå No unified context entries yet');
            console.log('üí° Unified context engine may not be running');
        }
    } else {
        console.log('‚ùå Unified Context Engine not found or not initialized');
        console.log('üí° Try running the fix script first');
    }
    
    console.log('\nüìä CURRENT REAL-TIME DATA:');
    console.log('===========================');
    
    // Current screen text
    if (window.screenOCRMonitor && window.screenOCRMonitor.currentScreenText) {
        console.log('üëÅÔ∏è Current Screen Text:');
        console.log(`"${window.screenOCRMonitor.currentScreenText.substring(0, 200)}..."`);
    } else {
        console.log('üëÅÔ∏è Current Screen Text: None detected');
    }
    
    // Current audio context
    if (window.audioEnvironmentMonitor && window.audioEnvironmentMonitor.currentAudioContext) {
        const audio = window.audioEnvironmentMonitor.currentAudioContext;
        console.log('üéß Current Audio Context:');
        console.log(`   Type: ${audio.type}, Source: ${audio.source}, Confidence: ${audio.confidence?.toFixed(2)}`);
        if (audio.details) {
            console.log(`   Details:`, audio.details);
        }
    } else {
        console.log('üéß Current Audio Context: None detected');
    }
    
    // Current unified context
    if (window.unifiedContextEngine && window.unifiedContextEngine.currentContext) {
        const unified = window.unifiedContextEngine.currentContext.unified;
        console.log('üß† Current Unified Context:');
        console.log(`   Primary: ${unified.primaryContext}, Activity: ${unified.activity}`);
        console.log(`   Environment: ${unified.environment}, Focus: ${unified.focusLevel}`);
    } else {
        console.log('üß† Current Unified Context: None available');
    }
    
    console.log('\n‚úÖ TRANSCRIPT VIEWING COMPLETE');
    console.log('===============================');
    console.log('üí° If you see "None detected" everywhere, the monitoring system needs to be restarted');
    console.log('üí° Run fixAllMonitoringIssues() to restart monitoring');
}

// Test system audio directly
async function testSystemAudioNow() {
    console.log('\nüß™ TESTING SYSTEM AUDIO DETECTION NOW:');
    console.log('======================================');
    
    if (!window.electronAPI || !window.electronAPI.audioEnvironment) {
        console.error('‚ùå Electron Audio API not available');
        return;
    }
    
    try {
        console.log('üéµ Getting current audio context...');
        const audioContext = await window.electronAPI.audioEnvironment.getCurrentAudioContext();
        console.log('üìä Raw Audio Context:', audioContext);
        
        console.log('üîä Capturing system audio sources...');
        const audioSources = await window.electronAPI.audioEnvironment.captureSystemAudio();
        console.log('üìä Raw Audio Sources:', audioSources);
        
        // Interpret results
        if (audioContext.context === 'music') {
            console.log(`‚úÖ MUSIC DETECTED: ${audioContext.currentTrack || 'Unknown track'} (${audioContext.app || 'Unknown app'})`);
        } else if (audioContext.context === 'silence') {
            console.log('üîá SILENCE DETECTED (no music currently playing)');
        } else {
            console.log(`üéµ AUDIO DETECTED: ${audioContext.context} (volume: ${audioContext.volume})`);
        }
        
        if (audioSources.audioSources && audioSources.audioSources.length > 0) {
            console.log(`üîä ACTIVE AUDIO APPS: ${audioSources.audioSources.map(s => `${s.name} (${s.type})`).join(', ')}`);
        } else {
            console.log('üîá NO ACTIVE AUDIO APPLICATIONS DETECTED');
        }
        
    } catch (error) {
        console.error('‚ùå System audio test failed:', error);
    }
}

// Export functions
window.viewAllTranscripts = viewAllTranscripts;
window.testSystemAudioNow = testSystemAudioNow;

console.log('üí° Available commands:');
console.log('  ‚Ä¢ viewAllTranscripts() - See all detected screen and audio data');
console.log('  ‚Ä¢ testSystemAudioNow() - Test system audio detection right now');